{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter US Airline Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IshOqZNB6POh"
      },
      "source": [
        "# Twitter US Airline Sentiment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4Eouxvz5Rb3"
      },
      "source": [
        "## **Context:**\n",
        "\n",
        "- This dataset consists of tweets from airlines customer from USA.\n",
        "- Twitter data was scraped from February of 2015.\n",
        "- It also includes tweets from different airlines customer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaP-CPyF5Ndl"
      },
      "source": [
        "#### In this tweet, there is Positive/Negative/Neutral sentiment. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjnXaaLV5Qff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040b00ca-d175-468a-a52a-86b1fe29a2e0"
      },
      "source": [
        "# install and import necessary libraries.\n",
        "\n",
        "!pip install contractions\n",
        "\n",
        "import re, string, unicodedata                          # Import Regex, string and unicodedata.\n",
        "import contractions                                     # Import contractions library.\n",
        "from bs4 import BeautifulSoup                           # Import BeautifulSoup.\n",
        "\n",
        "import numpy as np                                      # Import numpy.\n",
        "import pandas as pd                                     # Import pandas.\n",
        "import nltk                                             # Import Natural Language Tool-Kit.\n",
        "\n",
        "nltk.download('stopwords')                              # Download Stopwords.\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords                       # Import stopwords.\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize  # Import Tokenizer.\n",
        "from nltk.stem.wordnet import WordNetLemmatizer         # Import Lemmatizer."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/ce/ad/d1c685967945a04f8596128b15a1ab56c51488f53312e953341af6ff22d1/contractions-0.0.43-py2.py3-none-any.whl\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 5.9MB/s \n",
            "\u001b[?25hCollecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 36.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81700 sha256=4286de146343835ce7cf0e910dc42b9401b900c568faf63d1c2a784f5c271973\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, Unidecode, textsearch, contractions\n",
            "Successfully installed Unidecode-1.1.1 contractions-0.0.43 pyahocorasick-1.4.0 textsearch-0.0.17\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2eBTAZbpy73",
        "outputId": "79236e90-ffba-46f1-f20c-53ea2c1560cc"
      },
      "source": [
        "# Mountage of Google Drive\n",
        " \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqIcJMJw7MAE"
      },
      "source": [
        "# Loading data into pandas dataframe\n",
        "data = pd.read_csv(\"/content/drive/My Drive/AIML/Deep Learning Session/NLP/Tweets.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAxBWyO29Qb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66e39ce-faee-4127-9b5c-5ce3849b0fcb"
      },
      "source": [
        "data.shape                                               # print shape of data."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAJWb__77ZNu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "7d6d7982-0f68-4d51-a648-e1b4021f53d3"
      },
      "source": [
        "data.head()                                              # Print first 5 rows of data."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m_zUuoDzu1s"
      },
      "source": [
        "# From data file , airline_sentiment and text columns are kept as these are useful for our analysis.\n",
        "\n",
        "data = data.loc[:, ['airline_sentiment', 'text']]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fi1xVk_0g1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c70086-d39e-4294-c54b-0404e254c9f6"
      },
      "source": [
        "data.isnull().sum(axis=0)                                # Checking for Null values."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "airline_sentiment    0\n",
              "text                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anF2Hby_zgos",
        "outputId": "77368778-81b1-4190-abe5-539b654c64bd"
      },
      "source": [
        "# Count of Positive/Negative/Neutral Sentiment\n",
        "airline_sentiment  = data['airline_sentiment'].value_counts()\n",
        "print(airline_sentiment)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative    9178\n",
            "neutral     3099\n",
            "positive    2363\n",
            "Name: airline_sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeIScfrX7sCd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "93e8cd51-3c88-4d74-e520-58e94eefad87"
      },
      "source": [
        "pd.set_option('display.max_colwidth', None) # Display full dataframe information (Non-turncated Text column.)\n",
        "\n",
        "data.head()                                 # Check first 5 rows of data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                            text\n",
              "0           neutral                                                                                             @VirginAmerica What @dhepburn said.\n",
              "1          positive                                                        @VirginAmerica plus you've added commercials to the experience... tacky.\n",
              "2           neutral                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!\n",
              "3          negative  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse\n",
              "4          negative                                                                         @VirginAmerica and it's a really big bad thing about it"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtWdbYiL79M6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41aae83-4b66-42df-ee13-e20958e626cf"
      },
      "source": [
        "data.shape                                # Shape of data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "377IfFic-Ihk"
      },
      "source": [
        "### Data Pre-processing:\n",
        "\n",
        "- Remove html tags.\n",
        "- Replace contractions in string. (e.g. replace I'm --> I am)\n",
        "- Remove numbers.\n",
        "- Tokenization\n",
        "- To remove Stopwords.\n",
        "- Lemmatized data\n",
        "\n",
        "We have used NLTK library to tokenize words , remove stopwords and lemmatize the remaining words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf3kMpGN7Lp9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "63f26823-6666-4a17-c9f3-d92962fc2e92"
      },
      "source": [
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "data['text'] = data['text'].apply(lambda x: strip_html(x))\n",
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                        text\n",
              "0           neutral                                                                                         @VirginAmerica What @dhepburn said.\n",
              "1          positive                                                    @VirginAmerica plus you've added commercials to the experience... tacky.\n",
              "2           neutral                                                     @VirginAmerica I didn't today... Must mean I need to take another trip!\n",
              "3          negative  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse\n",
              "4          negative                                                                     @VirginAmerica and it's a really big bad thing about it"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7NgnYq77Puy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "637de250-6c35-48ff-89e9-853637a2554f"
      },
      "source": [
        "def replace_contractions(text):\n",
        "    \"\"\"Replace contractions in string of text\"\"\"\n",
        "    return contractions.fix(text)\n",
        "\n",
        "data['text'] = data['text'].apply(lambda x: replace_contractions(x))\n",
        "data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you have added commercials to the experience... tacky.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I did not today... Must mean I need to take another trip!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it is really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it is a really big bad thing about it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                         text\n",
              "0           neutral                                                                                          @VirginAmerica What @dhepburn said.\n",
              "1          positive                                                   @VirginAmerica plus you have added commercials to the experience... tacky.\n",
              "2           neutral                                                     @VirginAmerica I did not today... Must mean I need to take another trip!\n",
              "3          negative  @VirginAmerica it is really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse\n",
              "4          negative                                                                     @VirginAmerica and it is a really big bad thing about it"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga8ArYYxAB_1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0488f5aa-e797-4121-ad3e-a20fd00d22e2"
      },
      "source": [
        "def remove_numbers(text):\n",
        "  text = re.sub(r'\\d+', '', text)\n",
        "  return text\n",
        "\n",
        "data['text'] = data['text'].apply(lambda x: remove_numbers(x))\n",
        "data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you have added commercials to the experience... tacky.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I did not today... Must mean I need to take another trip!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it is really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it is a really big bad thing about it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                         text\n",
              "0           neutral                                                                                          @VirginAmerica What @dhepburn said.\n",
              "1          positive                                                   @VirginAmerica plus you have added commercials to the experience... tacky.\n",
              "2           neutral                                                     @VirginAmerica I did not today... Must mean I need to take another trip!\n",
              "3          negative  @VirginAmerica it is really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse\n",
              "4          negative                                                                     @VirginAmerica and it is a really big bad thing about it"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0-yYsx68DxT"
      },
      "source": [
        "data['text'] = data.apply(lambda row: nltk.word_tokenize(row['text']), axis=1) # Tokenization of data"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcHbJJFfAlM2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "eaeb0c9a-ed01-40f6-890e-ce4becb9fcdf"
      },
      "source": [
        "data.head()                                                                    # Look at how tokenized data looks."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>[@, VirginAmerica, What, @, dhepburn, said, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>[@, VirginAmerica, plus, you, have, added, commercials, to, the, experience, ..., tacky, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>[@, VirginAmerica, I, did, not, today, ..., Must, mean, I, need, to, take, another, trip, !]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>[@, VirginAmerica, it, is, really, aggressive, to, blast, obnoxious, ``, entertainment, '', in, your, guests, ', faces, &amp;, they, have, little, recourse]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>[@, VirginAmerica, and, it, is, a, really, big, bad, thing, about, it]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                                                      text\n",
              "0           neutral                                                                                                            [@, VirginAmerica, What, @, dhepburn, said, .]\n",
              "1          positive                                                               [@, VirginAmerica, plus, you, have, added, commercials, to, the, experience, ..., tacky, .]\n",
              "2           neutral                                                              [@, VirginAmerica, I, did, not, today, ..., Must, mean, I, need, to, take, another, trip, !]\n",
              "3          negative  [@, VirginAmerica, it, is, really, aggressive, to, blast, obnoxious, ``, entertainment, '', in, your, guests, ', faces, &, they, have, little, recourse]\n",
              "4          negative                                                                                    [@, VirginAmerica, and, it, is, a, really, big, bad, thing, about, it]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWZwuXaC-4qy"
      },
      "source": [
        "stopwords = stopwords.words('english')\n",
        "\n",
        "customlist = ['not', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn',\n",
        "        \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\n",
        "        \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn',\n",
        "        \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "\n",
        "# Set custom stop-word's list as not, couldn't etc. words matter in Sentiment, so not removing them from original data.\n",
        "\n",
        "stopwords = list(set(stopwords) - set(customlist))                              "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZjCxefg7Et3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "571f3f20-6d51-4375-a617-442ec8668279"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords:\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def lemmatize_list(words):\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "      new_words.append(lemmatizer.lemmatize(word, pos='v'))\n",
        "    return new_words\n",
        "\n",
        "def normalize(words):\n",
        "    words = remove_non_ascii(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    words = remove_stopwords(words)\n",
        "    words = lemmatize_list(words)\n",
        "    return ' '.join(words)\n",
        "\n",
        "data['text'] = data.apply(lambda row: normalize(row['text']), axis=1)\n",
        "data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>virginamerica dhepburn say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>virginamerica plus add commercials experience tacky</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>virginamerica not today must mean need take another trip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>virginamerica really aggressive blast obnoxious entertainment guests face little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>virginamerica really big bad thing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                       text\n",
              "0           neutral                                                                 virginamerica dhepburn say\n",
              "1          positive                                        virginamerica plus add commercials experience tacky\n",
              "2           neutral                                   virginamerica not today must mean need take another trip\n",
              "3          negative  virginamerica really aggressive blast obnoxious entertainment guests face little recourse\n",
              "4          negative                                                         virginamerica really big bad thing"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JqH_4JWOurH"
      },
      "source": [
        "# Vectorization (Convert text data to numbers).\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=1000)                # Keep only 1000 features as number of features will increase the processing time.\n",
        "data_features = vectorizer.fit_transform(data['text'])\n",
        "\n",
        "data_features = data_features.toarray()                        # Convert the data features to array."
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-xSq6Y-YN3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82fd93d1-b7fa-4c18-f5df-48fbfcdf728e"
      },
      "source": [
        "data_features.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHMs9XQm8BQN"
      },
      "source": [
        "Y = pd.get_dummies(data['airline_sentiment']).values"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuBWTlx_ZlRo"
      },
      "source": [
        "# Split data into training and testing set.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_features, Y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrRKfuzXXyPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d72315-91ec-4fc6-8b09-acda17280a40"
      },
      "source": [
        "# Using Random Forest to build model for the classification of reviews.\n",
        "# Also calculating the cross validation score.\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=20, n_jobs=10)\n",
        "\n",
        "forest = forest.fit(X_train, y_train)\n",
        "\n",
        "print(forest)\n",
        "\n",
        "print(np.mean(cross_val_score(forest, data_features, Y, cv=10)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=10,\n",
            "                       oob_score=False, random_state=None, verbose=0,\n",
            "                       warm_start=False)\n",
            "0.6848360655737704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuwujDwkZIW7"
      },
      "source": [
        "# Predict the result for test data using the model built above.\n",
        "\n",
        "result = forest.predict(X_test)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9mcIy8Q94MQ",
        "outputId": "a85ca0f4-b7fe-40a4-afac-d414aad31c30"
      },
      "source": [
        "result"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       ...,\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxs5Edx3InJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad27527d-447c-420c-812d-f12cabd02839"
      },
      "source": [
        "# Checking Accuracy\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "y_probs_train = forest.predict_proba(X_train)\r\n",
        "y_probs_test = forest.predict_proba(X_test)\r\n",
        "y_predicted_train = forest.predict(X_train)\r\n",
        "y_predicted_test = forest.predict(X_test)\r\n",
        "\r\n",
        "train_acc = accuracy_score(y_train, y_predicted_train)\r\n",
        "test_acc = accuracy_score(y_test, y_predicted_test)\r\n",
        "\r\n",
        "print('Train Accuracy: %.3f' % train_acc)\r\n",
        "print('Test Accuracy: %.3f' % test_acc)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.980\n",
            "Test Accuracy: 0.711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyWqFm4Bu8gX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bdb6dea-28c8-4f58-e760-330160f3e030"
      },
      "source": [
        "# Using TfidfVectorizer to convert text data to numbers.\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "data_features = vectorizer.fit_transform(data['text'])\n",
        "\n",
        "data_features = data_features.toarray()\n",
        "\n",
        "data_features.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7223wy58vjJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b81c73b-7f02-45cc-ce79-5252b04b0a43"
      },
      "source": [
        "# Using Random Forest to build model for the classification of reviews.\n",
        "# Also calculating the cross validation score.\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=20, n_jobs=10)\n",
        "\n",
        "forest = forest.fit(X_train, y_train)\n",
        "\n",
        "print(forest)\n",
        "\n",
        "print(np.mean(cross_val_score(forest, data_features, Y, cv=10)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=10,\n",
            "                       oob_score=False, random_state=None, verbose=0,\n",
            "                       warm_start=False)\n",
            "0.6945355191256831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxMaBRnLvl_A"
      },
      "source": [
        "result = forest.predict(X_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFkEFqU3vnbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c9b8bc-941a-4cdc-cf4c-1f27c30fc89e"
      },
      "source": [
        "# Checking Accuracy\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "y_probs_train = forest.predict_proba(X_train)\r\n",
        "y_probs_test = forest.predict_proba(X_test)\r\n",
        "y_predicted_train = forest.predict(X_train)\r\n",
        "y_predicted_test = forest.predict(X_test)\r\n",
        "\r\n",
        "train_acc = accuracy_score(y_train, y_predicted_train)\r\n",
        "test_acc = accuracy_score(y_test, y_predicted_test)\r\n",
        "\r\n",
        "print('Train Accuracy: %.3f' % train_acc)\r\n",
        "print('Test Accuracy: %.3f' % test_acc)\r\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.979\n",
            "Test Accuracy: 0.705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwxfFdwhc-9o"
      },
      "source": [
        "Summary:\n",
        "\n",
        "- There is Tweets dataset which has reviews in text format and their sentiment are Positive/Negative/Neutral.\n",
        "- The goal was to build a model for text-classification.\n",
        "- The data is processed using variuos techniques and libraries.\n",
        "- The pre-processed data is converted to numbers which is suitable for model.\n",
        "- After building the classification model, we predicted the result for the test data.\n",
        "- Train Accuracy is much higher and train accuracy is bad. There is overfitting in model. The Accuracy could be increased by using different preprocessing techniques and methods used.\n"
      ]
    }
  ]
}